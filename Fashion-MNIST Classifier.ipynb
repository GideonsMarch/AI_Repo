{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemArray = [\"T-Shirt/Top\", \"Trouser\", \"Pull over\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.FashionMNIST(root = './mnist/data', download = True, train = True, transform = transform)\n",
    "testset = datasets.FashionMNIST(root = './mnist/data/Test', download = True, train = False, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim = 1))  #define the model\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  0.3526656534403627\n",
      "Training loss:  0.3436314513974347\n",
      "Training loss:  0.33570990409614637\n",
      "Training loss:  0.3269453694475997\n",
      "Training loss:  0.3190701330171978\n",
      "Training loss:  0.3119076583494763\n",
      "Training loss:  0.30552163805915833\n",
      "Training loss:  0.29830117596746303\n",
      "Training loss:  0.2915236997340659\n",
      "Training loss:  0.2856513839175323\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logps = model.forward(images)\n",
    "        loss = criterion(logps, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() / (len(trainloader))\n",
    "        \n",
    "    else:\n",
    "        print(f\"Training loss: \", running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: Shirt, probability: 0.703930675983429\n",
      "Model prediction using the topk method: Shirt, probability: 0.703930675983429\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageTestBatch, labelTestBatch = next(iter(testloader))\n",
    "plt.imshow(imageTestBatch[0][0].numpy(), cmap='gray')\n",
    "\n",
    "predictionTest = model.forward(imageTestBatch[0].view(1, -1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    ps = F.softmax(predictionTest, dim = 1)\n",
    "    \n",
    "    maximum = torch.max(ps)\n",
    "    itemIndex = (ps == maximum).nonzero()[0][1].item()\n",
    "    print(f\"Model prediction: {itemArray[itemIndex]}, probability: {maximum}\")\n",
    "    \n",
    "    result = ps.topk(1, dim=1) #Returns the top 1 value of the tensor. if 2 is used instead of 1, it returns the 2 highests.\n",
    "    print(f\"Model prediction using the topk method: {itemArray[result[1].item()]}, probability: {result[0].item()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
