{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config inlineBackend.figure_format = \"retina\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "#import helper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "#import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return (1 / (1 + torch.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(root = './data', download = True, train = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, label = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n"
     ]
    }
   ],
   "source": [
    "inputs = images.view(64, -1)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(7)\n",
    "\n",
    "W1 = torch.randn(784, 256)\n",
    "B1 = torch.randn(256)\n",
    "\n",
    "W2 = torch.randn(256, 10)\n",
    "B2 = torch.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = activation(torch.mm(inputs, W1) + B1)\n",
    "\n",
    "h_output = torch.mm(h1, W2) + B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2.8918,  -5.7706,   6.3215,  -2.4816,  -8.7866,   9.0465,  -1.3260,\n",
       "         -0.1009,   1.2504, -12.0129])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = torch.exp(x)\n",
    "    output_sum = torch.sum(x, dim = 1)\n",
    "    return (x / output_sum.view(output_sum.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "output_tensor = softmax(h_output)\n",
    "print(torch.sum(output_tensor, dim = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing the NN module (Training procedure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Negative-Log-Likelihood loss.</b>\n",
    "Think of this as dot product of the hot-encoded label vector (e.g [0, 0, 0, 0, 0, 0, 1, 0, 0, 0 ] for label 7) and the output probabilty vector (e.g [0.0023, 0.00132,... 0.3477...] for label 7). This will produce a sum: 0 + 0 + 0 + 0 + 0 + 0 + 0.3477 + 0 + 0 + 0 = 0.3477. This is very low and thus knows there's a need for more training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim = 1))  #define the model\n",
    "\n",
    "criterion = nn.NLLLoss() #define the loss function. \n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01) #define optimization function. SGD. Responsible for updating the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0732263112500278\n",
      "Training loss: 0.392752694994656\n",
      "Training loss: 0.3284683593475361\n",
      "Training loss: 0.29699987728299615\n",
      "Training loss: 0.2715720067273325\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    running_loss = 0\n",
    "    for images, label in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        optimizer.zero_grad() #empty all gradients\n",
    "\n",
    "        logits = model.forward(images)  #Run a forward pass \n",
    "        loss = criterion(logits, label) #Calculate the loss matrix between the label and the predictions (images.shape[0], 10)\n",
    "        \n",
    "        loss.backward()  #Calculate and populate the gradients from the loss to all parameters: weights from input to loss\n",
    "        optimizer.step() #calculate the new values based on the gradients at each weight/node.\n",
    "        \n",
    "        running_loss += loss.item() # .item() gets the real value of the tensor\n",
    "        \n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = datasets.MNIST(root = './data', download = False, train = False, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, label = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "img = images[4].view(1, 784)\n",
    "print(label[4].item())\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "    \n",
    "ps = F.softmax(logits, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0159,  0.0214, -0.0183,  ...,  0.0027, -0.0114, -0.0105],\n",
      "        [-0.0285, -0.0176, -0.0036,  ...,  0.0172, -0.0122, -0.0057],\n",
      "        [ 0.0301, -0.0019, -0.0217,  ...,  0.0204, -0.0005,  0.0285],\n",
      "        ...,\n",
      "        [ 0.0166, -0.0106,  0.0016,  ..., -0.0009,  0.0190, -0.0051],\n",
      "        [ 0.0323, -0.0122,  0.0114,  ..., -0.0092,  0.0064, -0.0314],\n",
      "        [-0.0155,  0.0021,  0.0133,  ..., -0.0047, -0.0085, -0.0038]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Label: 5\n",
      "Index: 1, Label: 5\n",
      "Index: 2, Label: 7\n",
      "Index: 3, Label: 6\n",
      "Index: 4, Label: 8\n",
      "Index: 5, Label: 8\n",
      "Index: 6, Label: 4\n",
      "Index: 7, Label: 5\n",
      "Index: 8, Label: 2\n",
      "Index: 9, Label: 9\n",
      "Index: 10, Label: 0\n",
      "Index: 11, Label: 0\n",
      "Index: 12, Label: 3\n",
      "Index: 13, Label: 7\n",
      "Index: 14, Label: 9\n",
      "Index: 15, Label: 2\n",
      "Index: 16, Label: 4\n",
      "Index: 17, Label: 1\n",
      "Index: 18, Label: 3\n",
      "Index: 19, Label: 8\n",
      "Index: 20, Label: 6\n",
      "Index: 21, Label: 6\n",
      "Index: 22, Label: 3\n",
      "Index: 23, Label: 0\n",
      "Index: 24, Label: 3\n",
      "Index: 25, Label: 2\n",
      "Index: 26, Label: 8\n",
      "Index: 27, Label: 8\n",
      "Index: 28, Label: 7\n",
      "Index: 29, Label: 7\n",
      "Index: 30, Label: 7\n",
      "Index: 31, Label: 4\n",
      "Index: 32, Label: 2\n",
      "Index: 33, Label: 9\n",
      "Index: 34, Label: 8\n",
      "Index: 35, Label: 7\n",
      "Index: 36, Label: 2\n",
      "Index: 37, Label: 1\n",
      "Index: 38, Label: 0\n",
      "Index: 39, Label: 2\n",
      "Index: 40, Label: 3\n",
      "Index: 41, Label: 5\n",
      "Index: 42, Label: 4\n",
      "Index: 43, Label: 3\n",
      "Index: 44, Label: 5\n",
      "Index: 45, Label: 1\n",
      "Index: 46, Label: 5\n",
      "Index: 47, Label: 9\n",
      "Index: 48, Label: 3\n",
      "Index: 49, Label: 5\n",
      "Index: 50, Label: 8\n",
      "Index: 51, Label: 1\n",
      "Index: 52, Label: 2\n",
      "Index: 53, Label: 6\n",
      "Index: 54, Label: 9\n",
      "Index: 55, Label: 9\n",
      "Index: 56, Label: 1\n",
      "Index: 57, Label: 6\n",
      "Index: 58, Label: 2\n",
      "Index: 59, Label: 6\n",
      "Index: 60, Label: 3\n",
      "Index: 61, Label: 4\n",
      "Index: 62, Label: 2\n",
      "Index: 63, Label: 6\n"
     ]
    }
   ],
   "source": [
    "for index, ground_truth in zip(range(64), label):\n",
    "    print(f\"Index: {index}, Label: {ground_truth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
